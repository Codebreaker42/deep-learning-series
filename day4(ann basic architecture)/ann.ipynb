{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          400 non-null    int64  \n",
      " 1   TOEFL Score        400 non-null    int64  \n",
      " 2   University Rating  400 non-null    int64  \n",
      " 3   SOP                400 non-null    float64\n",
      " 4   LOR                400 non-null    float64\n",
      " 5   CGPA               400 non-null    float64\n",
      " 6   Research           400 non-null    int64  \n",
      " 7   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 25.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.807500</td>\n",
       "      <td>107.410000</td>\n",
       "      <td>3.087500</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.452500</td>\n",
       "      <td>8.598925</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.724350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.473646</td>\n",
       "      <td>6.069514</td>\n",
       "      <td>1.143728</td>\n",
       "      <td>1.006869</td>\n",
       "      <td>0.898478</td>\n",
       "      <td>0.596317</td>\n",
       "      <td>0.498362</td>\n",
       "      <td>0.142609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.062500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GRE Score  TOEFL Score  University Rating         SOP        LOR   \\\n",
       "count  400.000000   400.000000         400.000000  400.000000  400.000000   \n",
       "mean   316.807500   107.410000           3.087500    3.400000    3.452500   \n",
       "std     11.473646     6.069514           1.143728    1.006869    0.898478   \n",
       "min    290.000000    92.000000           1.000000    1.000000    1.000000   \n",
       "25%    308.000000   103.000000           2.000000    2.500000    3.000000   \n",
       "50%    317.000000   107.000000           3.000000    3.500000    3.500000   \n",
       "75%    325.000000   112.000000           4.000000    4.000000    4.000000   \n",
       "max    340.000000   120.000000           5.000000    5.000000    5.000000   \n",
       "\n",
       "             CGPA    Research  Chance of Admit   \n",
       "count  400.000000  400.000000        400.000000  \n",
       "mean     8.598925    0.547500          0.724350  \n",
       "std      0.596317    0.498362          0.142609  \n",
       "min      6.800000    0.000000          0.340000  \n",
       "25%      8.170000    0.000000          0.640000  \n",
       "50%      8.610000    1.000000          0.730000  \n",
       "75%      9.062500    1.000000          0.830000  \n",
       "max      9.920000    1.000000          0.970000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df.iloc[:,0:7],df.iloc[:,-1],test_size=.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>319</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>320</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>327</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>340</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>320</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>336</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>329</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>306</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>302</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "381        319          105                  3  3.0   3.5  8.67         1\n",
       "55         320          103                  3  3.0   3.0  7.70         0\n",
       "76         327          112                  3  3.0   3.0  8.72         1\n",
       "25         340          120                  5  4.5   4.5  9.60         1\n",
       "82         320          110                  5  5.0   4.5  9.22         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "71         336          112                  5  5.0   5.0  9.76         1\n",
       "106        329          111                  4  4.5   4.5  9.18         1\n",
       "270        306          105                  2  2.5   3.0  8.22         1\n",
       "348        302           99                  1  2.0   2.0  7.25         0\n",
       "102        314          106                  2  4.0   3.5  8.25         0\n",
       "\n",
       "[360 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>301</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>311</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>340</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>325</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>301</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>340</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>297</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>303</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>312</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>323</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>323</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>334</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>316</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>313</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>308</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>297</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>335</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>301</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>314</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>318</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>299</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>311</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>296</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>308</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>326</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>336</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>312</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>298</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>312</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>299</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>320</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>308</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>306</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>332</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "209        301          104                  3  3.5   4.0  8.12         1\n",
       "280        311          102                  3  4.5   4.0  8.64         1\n",
       "33         340          114                  5  4.0   4.0  9.60         1\n",
       "210        325          108                  4  4.5   4.0  9.06         1\n",
       "93         301           97                  2  3.0   3.0  7.88         1\n",
       "84         340          115                  5  4.5   4.5  9.45         1\n",
       "329        297           96                  2  2.5   1.5  7.89         0\n",
       "94         303           99                  3  2.0   2.5  7.66         0\n",
       "266        312          105                  2  2.0   2.5  8.45         0\n",
       "126        323          113                  3  4.0   3.0  9.32         1\n",
       "9          323          108                  3  3.5   3.0  8.60         0\n",
       "361        334          116                  4  4.0   3.5  9.54         1\n",
       "56         316          102                  3  2.0   3.0  7.40         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "132        309          105                  5  3.5   3.5  8.56         0\n",
       "42         313          107                  2  2.5   2.0  8.50         1\n",
       "278        308          103                  2  3.0   3.5  8.49         0\n",
       "376        297           96                  2  2.5   2.0  7.43         0\n",
       "231        319          106                  3  3.5   2.5  8.33         1\n",
       "385        335          117                  5  5.0   5.0  9.82         1\n",
       "77         301           99                  2  3.0   2.0  8.22         0\n",
       "15         314          105                  3  3.5   2.5  8.30         0\n",
       "391        318          106                  3  2.0   3.0  8.65         0\n",
       "271        299           96                  2  1.5   2.0  7.86         0\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "114        311          105                  3  3.5   3.0  8.45         1\n",
       "225        296           99                  2  2.5   2.5  8.03         0\n",
       "262        308          103                  2  2.5   4.0  8.36         1\n",
       "104        326          112                  3  3.5   3.0  9.05         1\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "193        336          118                  5  4.5   5.0  9.53         1\n",
       "261        312          104                  3  3.5   4.0  8.09         0\n",
       "57         298           99                  2  4.0   2.0  7.60         0\n",
       "232        312          107                  2  2.5   3.5  8.27         0\n",
       "116        299          102                  3  4.0   3.5  8.62         0\n",
       "113        320          110                  2  4.0   3.5  8.56         0\n",
       "342        308          106                  3  3.0   3.0  8.24         0\n",
       "158        306          106                  2  2.0   2.5  8.14         0\n",
       "141        332          118                  2  4.5   3.5  9.36         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381    0.73\n",
       "55     0.64\n",
       "76     0.74\n",
       "25     0.94\n",
       "82     0.92\n",
       "       ... \n",
       "71     0.96\n",
       "106    0.87\n",
       "270    0.72\n",
       "348    0.57\n",
       "102    0.62\n",
       "Name: Chance of Admit , Length: 360, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209    0.68\n",
       "280    0.68\n",
       "33     0.90\n",
       "210    0.79\n",
       "93     0.44\n",
       "84     0.94\n",
       "329    0.43\n",
       "94     0.36\n",
       "266    0.72\n",
       "126    0.85\n",
       "9      0.45\n",
       "361    0.93\n",
       "56     0.64\n",
       "72     0.93\n",
       "132    0.71\n",
       "42     0.53\n",
       "278    0.66\n",
       "376    0.34\n",
       "231    0.74\n",
       "385    0.96\n",
       "77     0.64\n",
       "15     0.54\n",
       "391    0.71\n",
       "271    0.54\n",
       "0      0.92\n",
       "396    0.84\n",
       "114    0.59\n",
       "225    0.61\n",
       "262    0.70\n",
       "104    0.74\n",
       "395    0.82\n",
       "193    0.94\n",
       "261    0.71\n",
       "57     0.46\n",
       "232    0.69\n",
       "116    0.56\n",
       "113    0.72\n",
       "342    0.58\n",
       "158    0.61\n",
       "141    0.90\n",
       "Name: Chance of Admit , dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# making object \n",
    "mms=MinMaxScaler()\n",
    "# fit only training data \n",
    "mms.fit(x_train)\n",
    "# transform on both training and test data \n",
    "x_train=mms.transform(x_train)\n",
    "x_test=mms.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating sequential model object\n",
    "model=Sequential()\n",
    "# hidden layer-1\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "#hidden layer-2 \n",
    "model.add(Dense(7,activation='relu'))\n",
    "#output layer\n",
    "model.add(Dense(1,activation='linear')) # in case of regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120 (480.00 Byte)\n",
      "Trainable params: 120 (480.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='mean_squared_error',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit model and save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 54ms/step - loss: 0.9173 - accuracy: 0.0000e+00 - val_loss: 0.8946 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7821 - accuracy: 0.0000e+00 - val_loss: 0.7555 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6604 - accuracy: 0.0000e+00 - val_loss: 0.6311 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5508 - accuracy: 0.0000e+00 - val_loss: 0.5217 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4528 - accuracy: 0.0000e+00 - val_loss: 0.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3728 - accuracy: 0.0000e+00 - val_loss: 0.3472 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3052 - accuracy: 0.0000e+00 - val_loss: 0.2832 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2543 - accuracy: 0.0000e+00 - val_loss: 0.2389 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2205 - accuracy: 0.0000e+00 - val_loss: 0.2079 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1937 - accuracy: 0.0000e+00 - val_loss: 0.1809 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1691 - accuracy: 0.0000e+00 - val_loss: 0.1551 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1306 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1224 - accuracy: 0.0000e+00 - val_loss: 0.1080 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1017 - accuracy: 0.0000e+00 - val_loss: 0.0877 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0834 - accuracy: 0.0000e+00 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0672 - accuracy: 0.0000e+00 - val_loss: 0.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0536 - accuracy: 0.0000e+00 - val_loss: 0.0429 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0426 - accuracy: 0.0000e+00 - val_loss: 0.0333 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0339 - accuracy: 0.0000e+00 - val_loss: 0.0260 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0272 - accuracy: 0.0000e+00 - val_loss: 0.0207 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.0000e+00 - val_loss: 0.0148 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0134 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,batch_size=50,epochs=100,validation_split=.2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7430406604511139"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
